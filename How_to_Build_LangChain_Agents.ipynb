{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarunku/open_llm/blob/main/How_to_Build_LangChain_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nnYqN864i_28"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langgraph langchain-openai langchain_community  transformers torch accelerate bitsandbytes wikipedia youtube_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvfoqKiWkRfk"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun  # pip install wikipedia\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import YouTubeSearchTool  # pip install youtube_search\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.openai_dalle_image_generation import (\n",
        "   OpenAIDALLEImageGenerationTool\n",
        ")\n",
        "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
        "\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TextStreamer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoModelForSpeechSeq2Seq,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "import os\n",
        "\n",
        "from IPython.display import Image, display, YouTubeVideo\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTudyikgKYMO"
      },
      "outputs": [],
      "source": [
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE4-cfw-KmEP"
      },
      "outputs": [],
      "source": [
        "def load_pipeline(READER_MODEL_NAME):\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "  )\n",
        "\n",
        "  # Ensure proper device placement\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(f\"Loading model on: {device}\")\n",
        "\n",
        "  model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, device_map=\"auto\", quantization_config=bnb_config)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "  streamer = TextStreamer(tokenizer, timeout=600) # Increased timeout to 120 seconds\n",
        "\n",
        "\n",
        "  text_gen_pipeline = pipeline(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        task=\"text-generation\",\n",
        "        do_sample=True,\n",
        "        temperature=0.2,\n",
        "        repetition_penalty=1.1,\n",
        "        return_full_text=False,\n",
        "        max_new_tokens=250,\n",
        "        streamer=streamer\n",
        "    )\n",
        "\n",
        "  return text_gen_pipeline, tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo4NMjnvKpsq"
      },
      "outputs": [],
      "source": [
        "# Set up the OpenAI model,\n",
        "openai_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "# Set up the Opensource model,\n",
        "\n",
        "pipeline, tokenizer = load_pipeline(\"HuggingFaceH4/zephyr-7b-beta\")\n",
        "#pipeline, tokenizer = load_pipeline(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "os_llm = HuggingFacePipeline(\n",
        "    pipeline=pipeline\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model is on: {pipeline.model.device}\")"
      ],
      "metadata": {
        "id": "Vf330b9TtOim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(\"Test input\", return_tensors=\"pt\")  # Convert text to tensor\n",
        "print(f\"Tokenizer outputs are on: {tokens['input_ids'].device}\")"
      ],
      "metadata": {
        "id": "y_X42yM7tjky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_on_cuda(text):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\")  # Tokenize\n",
        "    return {key: value.to(device) for key, value in tokens.items()}\n",
        "\n",
        "tokens = tokenize_on_cuda(\"Example input\")\n",
        "print(tokens['input_ids'].device)  # Should be cuda:0"
      ],
      "metadata": {
        "id": "CSjNsStduAHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_L4gNQHknbR"
      },
      "source": [
        "When a user queries our agent, it will decide whether to explain the topic using a Wikipedia article in text format, or by creating an image using Dall-E for visual understanding, or by suggesting YouTube videos for deeper comprehension.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjAKyfWoBRqd"
      },
      "outputs": [],
      "source": [
        "#Tools\n",
        "\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def wikipedia(toic:str):\n",
        "  print(\"wikipedia**************\")\n",
        "  wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
        "  wikipedia = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
        "  return wikipedia.invoke(toic)\n",
        "\n",
        "\n",
        "def dalle(topic:str):\n",
        "  dalle_api_wrapper = DallEAPIWrapper(model=\"dall-e-3\", size=\"1024x1024\")\n",
        "\n",
        "  dalle = OpenAIDALLEImageGenerationTool(\n",
        "    api_wrapper=dalle_api_wrapper\n",
        "  )\n",
        "\n",
        "  image_url = dalle.invoke(topic)\n",
        "  return image_url\n",
        "\n",
        "def youtube(topic:str):\n",
        "  youtube = YouTubeSearchTool()\n",
        "  results = youtube.run(topic)\n",
        "  results_list = ast.literal_eval(results)\n",
        "  return results_list\n",
        "\n",
        "#results = youtube(\"Winmore Academy Whitefiele Bangalore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QeWv86ODW32"
      },
      "outputs": [],
      "source": [
        "#Agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from langchain.agents import (\n",
        "    create_react_agent,\n",
        "    AgentExecutor\n",
        ")\n",
        "from langchain import hub\n",
        "\n",
        "llm = openai_llm\n",
        "#llm = os_llm\n",
        "\n",
        "\n",
        "def agent_007(topic: str) -> str:\n",
        "\n",
        "    template = \"\"\"\n",
        "   You are a helpful bot named Chandler. Your task is to explain topic {topic_name}\n",
        "   asked by the user via three mediums: text, image or video.\n",
        "\n",
        "   If the asked topic is best explained in text format, use the Wikipedia tool.\n",
        "   If the topic is best explained by showing a picture of it, generate an image\n",
        "   of the topic using Dall-E image generator and print the image URL.\n",
        "   Finally, if video is the best medium to explain the topic, conduct a YouTube search on it\n",
        "   and return found video links.\n",
        "   \"\"\"\n",
        "\n",
        "    prompt_template = PromptTemplate(\n",
        "        template=template, input_variables=[\"topic_name\"]\n",
        "    )\n",
        "\n",
        "    tools_for_agent = [\n",
        "        Tool(\n",
        "            name=\"Wikipedia tool\",\n",
        "            func=wikipedia,\n",
        "            description=\"A tool to explain things in text format. Use this tool if you think the user’s asked concept is best explained through text.\",\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"Dall-E image generator\",\n",
        "            func=dalle,\n",
        "            description=\"A tool to generate images. Use this tool if you think the user’s asked concept is best explained through an image.\",\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"Youtube Search tool\",\n",
        "            func=youtube,\n",
        "            description=\"A tool to search YouTube videos. Use this tool if you think the user’s asked concept can be best explained by watching a video.\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    react_prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "    agent = create_react_agent(llm=llm, tools=tools_for_agent, prompt=react_prompt)\n",
        "    agent_executor = AgentExecutor(agent=agent, tools=tools_for_agent, verbose=True)\n",
        "\n",
        "\n",
        "    result = agent_executor.invoke(\n",
        "        input={\"input\": prompt_template.format_prompt(topic_name=topic)}\n",
        "    )\n",
        "\n",
        "    return result[\"output\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKkI_goHBRiB"
      },
      "outputs": [],
      "source": [
        "agent_007('what is the most famous michael jackson song on youtube?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwhnNu6bIP68"
      },
      "outputs": [],
      "source": [
        "agent_007('Hows the bangalore city traffic looks like in a normal working day?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB_7hqbZIhqq"
      },
      "outputs": [],
      "source": [
        "agent_007('Narendra Modi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53S4A8YJIzth"
      },
      "outputs": [],
      "source": [
        "agent_007('a visual representation of the earth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cauauieQJHXG"
      },
      "outputs": [],
      "source": [
        "display(Image(url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-uZ8XGmBrCDbMMojRLEFKSmvM/user-jJY7mx87k1jPs2adt0yL2vAG/img-QMc6i0dCQoA4A8xKqLXF8Xxs.png?st=2025-03-30T07%3A20%3A58Z&se=2025-03-30T09%3A20%3A58Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-03-30T07%3A07%3A17Z&ske=2025-03-31T07%3A07%3A17Z&sks=b&skv=2024-08-04&sig=vNOcwCjJ0eHU5reVy0itPnoUih%2Bzz5uy13XkuOyb0fM%3D'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNkyrTE6CxWX/1GGETcTRhb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}